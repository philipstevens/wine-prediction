{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Plot / Graph stuffs\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "import sklearn.metrics as metrics #import confusion_matrix, classification_report\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "from subprocess import check_output\n",
    "print(check_output([\"ls\", \"../data_root/raw\"]).decode(\"utf8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "loaded_model = pickle.load(open('../data_root/model/model.pickle', 'rb'))\n",
    "\n",
    "in_data = '../data_root/processed/test.parquet.gzip'\n",
    "\n",
    "test = pd.read_parquet(in_data)\n",
    "\n",
    "X_test = test.iloc[:,:-1]\n",
    "\n",
    "y_test = test.iloc[:,-1]\n",
    "\n",
    "predictions = loaded_model.predict(X_test)\n",
    "\n",
    "print(\"Results of random regressor on price and description length only:\" )\n",
    "print(\"explained_variance_score: \", metrics.explained_variance_score(y_test, predictions)) #Explained variance regression score function\n",
    "print(\"max_error: \", metrics.max_error(y_test, predictions)) #max_error metric calculates the maximum residual error.\n",
    "print(\"mean absolute error: \", metrics.mean_absolute_error(y_test, predictions)) #Mean absolute error regression loss\n",
    "print(\"mean squared error: \", metrics.mean_squared_error(y_test, predictions)) #Mean squared error regression loss\n",
    "print(\"mean squared log error: \", metrics.mean_squared_log_error(y_test, predictions)) #Mean squared logarithmic error regression loss\n",
    "print(\"median absolute error: \", metrics.median_absolute_error(y_test, predictions)) #Median absolute error regression loss\n",
    "print(\"R2 score: \", metrics.r2_score(y_test, predictions)) #R^2 (coefficient of determination) regression score function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_csv = '../data_root/raw/wine_dataset.csv'\n",
    "init_data = pd.read_csv(input_csv, index_col= 0)\n",
    "\n",
    "print(\"Number of rows before processing:\", len(init_data))\n",
    "print()\n",
    "print(\"Summary of numerical columns: \")\n",
    "print(init_data.describe())\n",
    "print()\n",
    "print(\"Summary of missing data: \")\n",
    "print(init_data.isna().sum())\n",
    "print()\n",
    "print(\"Sample data: \")\n",
    "init_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "selected_data = init_data[['country', 'description', 'points', 'price', \n",
    "    'province', 'title', 'variety','winery']]\n",
    "\n",
    "deduped_data = selected_data[~selected_data.duplicated()]\n",
    "print(\"Number of rows after removing duplicates:\",\n",
    "      len(deduped_data))\n",
    "\n",
    "data = deduped_data.dropna()\n",
    "print(\"Number of rows after removing missing data:\" , len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(30,10))\n",
    "plt.xticks(fontsize=20) # X Ticks\n",
    "plt.yticks(fontsize=20) # Y Ticks\n",
    "ax.set_title('Number of wines per points', fontweight=\"bold\", size=25) # Title\n",
    "ax.set_ylabel('Number of wines', fontsize = 25) # Y label\n",
    "ax.set_xlabel('Points', fontsize = 25) # X label\n",
    "data.groupby(['points']).count()['description'].plot(ax=ax, kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.assign(description_length = data['description'].apply(len))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(30,10))\n",
    "sns.boxplot(x='points', y='description_length', data=data)\n",
    "plt.xticks(fontsize=20) # X Ticks\n",
    "plt.yticks(fontsize=20) # Y Ticks\n",
    "ax.set_title('Description Length per Points', fontweight=\"bold\", size=25) # Title\n",
    "ax.set_ylabel('Description Length', fontsize = 25) # Y label\n",
    "ax.set_xlabel('Points', fontsize = 25) # X label\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transform method taking points as param\n",
    "def transform_points_simplified(points):\n",
    "    if points < 86:\n",
    "        return 1\n",
    "    elif points >= 86 and points < 88:\n",
    "        return 2 \n",
    "    elif points >= 88 and points < 91:\n",
    "        return 3 \n",
    "    elif points >= 91:\n",
    "        return 4 \n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "#Applying transform method and assigning result to new column \"points_simplified\"\n",
    "data = data.assign(points_simplified = data['points'].apply(transform_points_simplified))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(30,10))\n",
    "plt.xticks(fontsize=20) # X Ticks\n",
    "plt.yticks(fontsize=20) # Y Ticks\n",
    "ax.set_title('Number of wines per points', fontweight=\"bold\", size=25) # Title\n",
    "ax.set_ylabel('Number of wines', fontsize = 25) # Y label\n",
    "ax.set_xlabel('Points', fontsize = 25) # X label\n",
    "data.groupby(['points_simplified']).count()['description'].plot(ax=ax, kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(30,10))\n",
    "sns.boxplot(x='points_simplified', y='description_length', data=data)\n",
    "plt.xticks(fontsize=20) # X Ticks\n",
    "plt.yticks(fontsize=20) # Y Ticks\n",
    "ax.set_title('Description Length per Points', fontweight=\"bold\", size=25) # Title\n",
    "ax.set_ylabel('Description Length', fontsize = 25) # Y label\n",
    "ax.set_xlabel('Points', fontsize = 25) # X label\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features = [\n",
    "    'country',\n",
    "    'province',\n",
    "    'variety',\n",
    "    'winery',\n",
    "]\n",
    "\n",
    "num_features = [\n",
    "    'price',\n",
    "    'description_length'\n",
    "]\n",
    "\n",
    "labels = ['points']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_num = data[num_features]\n",
    "y = data[labels]\n",
    "\n",
    "\n",
    "# Training model\n",
    "X_num_train, X_num_test, y_num_train, y_num_test = train_test_split(\n",
    "    X_num, y, test_size=0.1, random_state=101\n",
    ")\n",
    "\n",
    "rfr_num = RandomForestRegressor()\n",
    "rfr_num.fit(X_num_train, y_num_train)\n",
    "\n",
    "# Testing model\n",
    "predictions_num = rfr_num.predict(X_num_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#' % Linear Regression model with Python\n",
    "#' % Matti Pastell\n",
    "#' % 19.4.2013\n",
    "\n",
    "#' #Requirements\n",
    "#' This en example of doing linear regression analysis using Python\n",
    "#' and [statsmodels](http://statsmodels.sourceforge.net). We'll use the new formula API\n",
    "#' which makes fitting the models very familiar for R users.\n",
    "#' You'll also need [Numpy](http://www.numpy.org/), [Pandas](http://pandas.pydata.org/)\n",
    "#' and [matplolib](http://matplotlib.org/).\n",
    "\n",
    "#' The analysis can be published using  Pweave 0.22 and later.\n",
    "\n",
    "#' Import libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.formula.api as sm\n",
    "import statsmodels\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#' Statsmodels api seems to change often, check release version:\n",
    "#+ term=True\n",
    "\n",
    "statsmodels.__version__\n",
    "\n",
    "\n",
    "#' We'll use [whiteside](http://stat.ethz.ch/R-manual/R-patched/library/MASS/html/whiteside.html) dataset from R package MASS. You can read the description of the dataset from the link, but in short it contains:\n",
    "\n",
    "#' >*The weekly gas consumption and average external temperature at a house in south-east England for two\n",
    "#' heating seasons, one of 26 weeks before, and one of 30 weeks after cavity-wall insulation was installed.*\n",
    "\n",
    "#' Load dataset using Pandas:\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/mpastell/Rdatasets/master/csv/MASS/whiteside.csv'\n",
    "whiteside = pd.read_csv(url)\n",
    "\n",
    "#' # Fitting the model\n",
    "#' Let's see what the relationship between the gas consumption is before the insulation.\n",
    "#' See [statsmodels documentation](http://statsmodels.sourceforge.net/devel/example_formulas.html)\n",
    "#' for more information about the syntax.\n",
    "\n",
    "model = sm.ols(formula='Gas ~ Temp', data=whiteside, subset = whiteside['Insul']==\"Before\")\n",
    "fitted = model.fit()\n",
    "print(fitted.summary())\n",
    "\n",
    "#' # Plot the data and fit\n",
    "\n",
    "Before = whiteside[whiteside[\"Insul\"] == \"Before\"]\n",
    "plt.plot(Before[\"Temp\"], Before[\"Gas\"], 'ro')\n",
    "plt.plot(Before[\"Temp\"], fitted.fittedvalues, 'b')\n",
    "plt.legend(['Data', 'Fitted model'])\n",
    "plt.ylim(0, 10)\n",
    "plt.xlim(-2, 12)\n",
    "plt.xlabel('Temperature')\n",
    "plt.ylabel('Gas')\n",
    "plt.title('Before Insulation')\n",
    "\n",
    "#' # Fit diagnostiscs\n",
    "#' Statsmodels [OLSresults](http://statsmodels.sourceforge.net/devel/generated/statsmodels.regression.linear_model.OLSResults.html) objects contain the usual diagnostic information about the model and you can use the `get_influence()` method to get more diagnostic information (such as Cook's distance).\n",
    "\n",
    "#' ## A look at the residuals\n",
    "#' Histogram of normalized residuals\n",
    "\n",
    "plt.hist(fitted.resid_pearson)\n",
    "plt.ylabel('Count')\n",
    "plt.xlabel('Normalized residuals')\n",
    "\n",
    "\n",
    "#' ## Cooks distance\n",
    "\n",
    "#' [OLSInfluence](http://statsmodels.sourceforge.net/devel/generated/statsmodels.stats.outliers_influence.OLSInfluence.html)\n",
    "#'  objects contain more diagnostic information\n",
    "\n",
    "influence = fitted.get_influence()\n",
    "#c is the distance and p is p-value\n",
    "(c, p) = influence.cooks_distance\n",
    "plt.stem(np.arange(len(c)), c, markerfmt=\",\")\n",
    "\n",
    "\n",
    "#' # Statsmodels builtin plots\n",
    "\n",
    "#' Statsmodels includes a some builtin function for plotting residuals against leverage:\n",
    "\n",
    "from statsmodels.graphics.regressionplots import *\n",
    "plot_leverage_resid2(fitted)\n",
    "influence_plot(fitted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Results of random regressor on price and description length only:\" )\n",
    "print(\"explained_variance_score: \", metrics.explained_variance_score(y_num_test, predictions_num)) #Explained variance regression score function\n",
    "print(\"max_error: \", metrics.max_error(y_num_test, predictions_num)) #max_error metric calculates the maximum residual error.\n",
    "print(\"mean absolute error: \", metrics.mean_absolute_error(y_num_test, predictions_num)) #Mean absolute error regression loss\n",
    "print(\"mean squared error: \", metrics.mean_squared_error(y_num_test, predictions_num)) #Mean squared error regression loss\n",
    "print(\"mean squared log error: \", metrics.mean_squared_log_error(y_num_test, predictions_num)) #Mean squared logarithmic error regression loss\n",
    "print(\"median absolute error: \", metrics.median_absolute_error(y_num_test, predictions_num)) #Median absolute error regression loss\n",
    "print(\"R2 score: \", metrics.r2_score(y_num_test, predictions_num)) #R^2 (coefficient of determination) regression score function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cat = data[cat_features]\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "enc.fit(X_cat)\n",
    "X_cat_tfm = enc.transform(X_cat).toarray()\n",
    "X_cat_tfm = X_cat_tfm[:, np.where(np.sum(X_cat_tfm, axis=0) > 10)[0]]\n",
    "\n",
    "# Training model\n",
    "X_cat_train, X_cat_test, y_cat_train, y_cat_test = train_test_split(X_cat_tfm, y, test_size=0.1, random_state=101)\n",
    "rfr_cat = RandomForestRegressor()\n",
    "rfr_cat.fit(X_cat_train, y_cat_train)\n",
    "\n",
    "# Testing model\n",
    "predictions_cat = rfr_cat.predict(X_cat_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Results of random regressor on\", \", \".join(cat_features), \"only:\" )\n",
    "print(\"explained_variance_score: \", metrics.explained_variance_score(y_cat_test, predictions_cat)) #Explained variance regression score function\n",
    "print(\"max_error: \", metrics.max_error(y_cat_test, predictions_cat)) #max_error metric calculates the maximum residual error.\n",
    "print(\"mean absolute error: \", metrics.mean_absolute_error(y_cat_test, predictions_cat)) #Mean absolute error regression loss\n",
    "print(\"mean squared error: \", metrics.mean_squared_error(y_cat_test, predictions_cat)) #Mean squared error regression loss\n",
    "print(\"mean squared log error: \", metrics.mean_squared_log_error(y_cat_test, predictions_cat)) #Mean squared logarithmic error regression loss\n",
    "print(\"median absolute error: \", metrics.median_absolute_error(y_cat_test, predictions_cat)) #Median absolute error regression loss\n",
    "print(\"R2 score: \", metrics.r2_score(y_cat_test, predictions_cat)) #R^2 (coefficient of determination) regression score function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import hstack\n",
    "\n",
    "X_all = hstack([X_cat_tfm,X_num])\n",
    "\n",
    "# Training model\n",
    "X_all_train, X_all_test, y_all_train, y_all_test = train_test_split(X_all, y, test_size=0.1, random_state=101)\n",
    "rfr_all = RandomForestRegressor()\n",
    "rfr_all.fit(X_all_train, y_all_train)\n",
    "\n",
    "# Testing model\n",
    "predictions_all = rfr_all.predict(X_all_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Results of random regressor on all features except description:\" )\n",
    "print(\"explained_variance_score: \", metrics.explained_variance_score(y_all_test, predictions_all)) #Explained variance regression score function\n",
    "print(\"max_error: \", metrics.max_error(y_all_test, predictions_all)) #max_error metric calculates the maximum residual error.\n",
    "print(\"mean absolute error: \", metrics.mean_absolute_error(y_all_test, predictions_all)) #Mean absolute error regression loss\n",
    "print(\"mean squared error: \", metrics.mean_squared_error(y_all_test, predictions_cat)) #Mean squared error regression loss\n",
    "print(\"mean squared log error: \", metrics.mean_squared_log_error(y_all_test, predictions_all)) #Mean squared logarithmic error regression loss\n",
    "print(\"median absolute error: \", metrics.median_absolute_error(y_all_test, predictions_all)) #Median absolute error regression loss\n",
    "print(\"R2 score: \", metrics.r2_score(y_all_test, predictions_all)) #R^2 (coefficient of determination) regression score function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X = data['description']\n",
    "#y = data['points']\n",
    "\n",
    "#vectorizer = CountVectorizer()\n",
    "#vectorizer.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X = vectorizer.transform(X)\n",
    "#print('Shape of Sparse Matrix: ', X.shape)\n",
    "#print('Amount of Non-Zero occurrences: ', X.nnz)\n",
    "# Percentage of non-zero values\n",
    "#density = (100.0 * X.nnz / (X.shape[0] * X.shape[1]))\n",
    "#print('Density: {}'.format((density)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the model\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=101)\n",
    "#rfc = RandomForestRegressor(n_estimators=100,\n",
    "                            min_samples_leaf=2,\n",
    "                            max_features=\"sqrt\")\n",
    "#rfc.fit(X_train, y_train)\n",
    "\n",
    "# Testing the model\n",
    "#predictions = rfc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"explained_variance_score: \", metrics.explained_variance_score(y_test, predictions)) #Explained variance regression score function\n",
    "#print(\"max_error: \", metrics.max_error(y_test, predictions)) #max_error metric calculates the maximum residual error.\n",
    "#print(\"mean absolute error: \", metrics.mean_absolute_error(y_test, predictions)) #Mean absolute error regression loss\n",
    "#print(\"mean squared error: \", metrics.mean_squared_error(y_test, predictions)) #Mean squared error regression loss\n",
    "#print(\"mean squared log error: \", metrics.mean_squared_log_error(y_test, predictions)) #Mean squared logarithmic error regression loss\n",
    "#print(\"median absolute error: \", metrics.median_absolute_error(y_test, predictions)) #Median absolute error regression loss\n",
    "#print(\"R2 score: \", metrics.r2_score(y_test, predictions)) #R^2 (coefficient of determination) regression score function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X = data['description']\n",
    "#y = data['points_simplified']\n",
    "\n",
    "# Vectorizing model\n",
    "#vectorizer = TfidfVectorizer()\n",
    "#vectorizer.fit(X)\n",
    "#X = vectorizer.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training model\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=101)\n",
    "#rfc = RandomForestClassifier()\n",
    "#rfc.fit(X_train, y_train)\n",
    "\n",
    "# Testing model\n",
    "#predictions = rfc.predict(X_test)\n",
    "#print(classification_report(y_test, predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
